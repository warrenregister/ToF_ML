{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sys import path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.insert(0, '../src')\n",
    "from data_generator import DataGenerator\n",
    "from model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_transformation import get_better_spectra, get_precise_peaks\n",
    "dg = DataGenerator('../data/classification_cas_data.csv')\n",
    "norm_data = dg.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_better_spectra(dir='../data/SpectraCsvFiles_BkgndSubtractWatsonPeakFinder/')\n",
    "norm_data.sort_values('file_name', inplace=True)\n",
    "data.sort_values('file_name', inplace=True)\n",
    "norm_data = pd.merge(data, norm_data, on='file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = get_precise_peaks(norm_data, ['precise_channels', 'precise_intensities'])\n",
    "norm_data['peaks'] = peaks\n",
    "dg.set_df(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = dg.calibrated_df(True, use_ranges=True, cat=True)\n",
    "original_data['num_peaks'] = original_data['peaks'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_target(num):\n",
    "    if num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "original_data['new_target'] = original_data['target'].apply(get_new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961.7678321458432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(original_data['masses'].apply(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_transformation import get_isotope_data, get_isotope_mass_list\n",
    "isotope_data = get_isotope_data()\n",
    "nom_masses_low = get_isotope_mass_list(isotope_data, False, 2000)\n",
    "nom_masses_high = get_isotope_mass_list(isotope_data, True, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra(masses, intensities, nom_masses_low, nom_masses_high):\n",
    "    spectra = [0 for x in range(2000)]\n",
    "    spectra_intensities = [0 for x in range(2000)]\n",
    "    for i, mass in enumerate(masses):\n",
    "        j = round(mass)\n",
    "        num = mass - nom_masses_low[j]\n",
    "        spectra_intensities[j] = intensities[i]\n",
    "        if num < 0:\n",
    "            spectra[j] = num\n",
    "        else:\n",
    "            spectra[j] = mass - nom_masses_high[j]\n",
    "    return spectra, spectra_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "spectra = []\n",
    "intensities = []\n",
    "for row in original_data.itertuples():\n",
    "    a, b = get_spectra(row.masses, row.precise_intensities, nom_masses_low, nom_masses_high)\n",
    "    spectra.append(np.array(a))\n",
    "    intensities.append(np.array(b))\n",
    "spectra = np.vstack(spectra)\n",
    "intensities = np.vstack(intensities)\n",
    "scl = MinMaxScaler()\n",
    "scl.fit(intensities)\n",
    "intensities = scl.transform(intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dstack([spectra, intensities])\n",
    "y = original_data['new_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN / CNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input, Conv1D, AveragePooling1D\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def baseline_model():\n",
    "    x_in = Input(shape=(2000,))\n",
    "    dense1 = Dense(2000, activation='sigmoid')(x_in)\n",
    "    dense2 = Dense(2000, activation='sigmoid')(dense1)\n",
    "    dense3 = Dense(1000, activation='sigmoid')(dense2)\n",
    "    dense5 = Dense(2, activation='sigmoid')(dense3)\n",
    "    model = Model(inputs=x_in, outputs=dense5)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "results = cross_val_score(estimator, spectra, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454556345939637"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86263734, 0.87845302, 0.85635358, 0.8232044 , 0.80662984])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet Conv NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=8, kernel_size=20, activation='relu', input_shape=(2000, 2)))\n",
    "    model.add(AveragePooling1D())\n",
    "\n",
    "    model.add(Conv1D(filters=20, kernel_size=80, activation='relu'))\n",
    "    model.add(AveragePooling1D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=500, activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=2, activation = 'softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb70900b050>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = lenet, epochs = 100, batch_size = 10, verbose = 0)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421495327102803"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pd.get_dummies(y_test), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(preds)):\n",
    "    predictions.append(np.where(preds[i]==max(preds[i]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010989010989011"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Models with only offset error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_data = dg.calibrated_df(True, use_ranges=True,ranges=[0, 0, 0.5], cat=True)\n",
    "offset_data['num_peaks'] = original_data['peaks'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "intensities = []\n",
    "for row in offset_data.itertuples():\n",
    "    a, b = get_spectra(row.masses, row.precise_intensities, nom_masses_low, nom_masses_high)\n",
    "    spectra.append(np.array(a))\n",
    "    intensities.append(np.array(b))\n",
    "spectra = np.vstack(spectra)\n",
    "intensities = np.vstack(intensities)\n",
    "scl = MinMaxScaler()\n",
    "scl.fit(intensities)\n",
    "intensities = scl.transform(intensities)\n",
    "X = np.dstack([spectra, intensities])\n",
    "y = offset_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "results = cross_val_score(estimator, spectra, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5077287435531617"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = lenet, epochs = 100, batch_size = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49668508768081665"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, X, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulation Of Offset Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.set_df(norm_data)\n",
    "norm_data = dg.calibrated_df(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_carbon(data):\n",
    "    carbon_candidates = []\n",
    "    indices = []\n",
    "    for row in data.itertuples():\n",
    "        carb = 0\n",
    "        max = 0 \n",
    "        ind = -1\n",
    "        for i, mass in enumerate(row.masses):\n",
    "            if round(mass) == 12 and abs(mass - 12) < .01:\n",
    "                if row.intensities[i] > max:\n",
    "                    ind = i\n",
    "                    carb = mass\n",
    "                    max = row.intensities[i]\n",
    "        carb = abs(round(carb) - carb)\n",
    "        carbon_candidates.append(carb)\n",
    "    return carbon_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbs = np.array(check_for_carbon(offset_data))\n",
    "indices = pd.Series(carbs)!=0\n",
    "carbs = carbs[carbs!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbs = carbs.reshape(758, 1)\n",
    "a = carbs + carbs * 0.01\n",
    "b = carbs - carbs * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abs(np.hstack([carbs, a, b]))\n",
    "y = offset_data['target'][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from model_trainer import ModelTrainer\n",
    "models = [RandomForestClassifier, XGBClassifier, LGBMClassifier]\n",
    "mt = ModelTrainer(models, X, y, ['rfc', 'xgb', 'lgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accs, index_pred = mt.kfold_models(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_elements(data):\n",
    "    elements = []\n",
    "    for row in data.itertuples():\n",
    "        elems = [-1 for num in range(150)]\n",
    "        maxs = [-1 for num in range(150)] \n",
    "        inds = []\n",
    "        for i, mass in enumerate(row.masses):\n",
    "            index = round(mass)\n",
    "            if index < 150:\n",
    "                val = mass - index\n",
    "                if abs(mass - index) < .01:\n",
    "                    if row.intensities[i] > maxs[round(mass)]:\n",
    "                        maxs[index] = row.intensities[i]\n",
    "                        elems[index] = val\n",
    "        elems = pd.Series(elems)\n",
    "        elems = elems[elems != -1]\n",
    "        elements.append(list(elems))\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = check_for_elements(offset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(elements)\n",
    "data['target'] = offset_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[[1, 2, 3, 4 , 5, 6, 'target']].copy()\n",
    "a.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = a['target']\n",
    "X = a.drop('target', axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_add = X + X * 0.01\n",
    "X_sub = X - X * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([X, X_add, X_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier, XGBClassifier, LGBMClassifier]\n",
    "mt = ModelTrainer(models, X, y, ['rfc', 'xgb', 'lgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accs, index_pred = mt.kfold_models(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5336824779290739, 0.5642974711955708, 0.530046386353434]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    x_in = Input(shape=(18,))\n",
    "    dense1 = Dense(200, activation='sigmoid')(x_in)\n",
    "    dense2 = Dense(200, activation='sigmoid')(dense1)\n",
    "    dense3 = Dense(100, activation='sigmoid')(dense2)\n",
    "    dense5 = Dense(2, activation='sigmoid')(dense3)\n",
    "    model = Model(inputs=x_in, outputs=dense5)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "results = cross_val_score(estimator, X, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5116938471794128"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=2, kernel_size=2, activation='relu', input_shape=(18, 1)))\n",
    "    model.add(AveragePooling1D())\n",
    "\n",
    "    model.add(Conv1D(filters=1, kernel_size=4, activation='relu'))\n",
    "    model.add(AveragePooling1D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=500, activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=2, activation = 'softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.reshape((817, 18, 1)), y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb76c64f950>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "estimator = KerasClassifier(build_fn = lenet, epochs = 100, batch_size = 10, verbose = 0)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5426829268292683"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = estimator.predict_proba(X_test)\n",
    "predictions = []\n",
    "for i in range(len(preds)):\n",
    "    predictions.append(np.where(preds[i]==max(preds[i]))[0][0])\n",
    "roc_auc_score(pd.get_dummies(y_test), preds)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
