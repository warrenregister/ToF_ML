{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Offset Only.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"YOWShYSwhFXB","executionInfo":{"status":"ok","timestamp":1614977136631,"user_tz":480,"elapsed":1007,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sys import path\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKvWd6VjhGRL","executionInfo":{"status":"ok","timestamp":1614977158763,"user_tz":480,"elapsed":23063,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}},"outputId":"196a47bb-b471-44de-cdde-04c766a15ec2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nv0AxxOIhKGQ","executionInfo":{"status":"ok","timestamp":1614977159302,"user_tz":480,"elapsed":23595,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}},"outputId":"fb845999-12b0-48bc-c470-fa0a86092a53"},"source":["%cd /content/drive/My Drive/PHI/ToF_ML/src"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PHI/ToF_ML/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yxQeI5jbhFXG","executionInfo":{"status":"ok","timestamp":1614977161866,"user_tz":480,"elapsed":26157,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from setup import data_setup\n","from data_generator import DataGenerator\n","from model_trainer import ModelTrainer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"nn5iWg__hFXH","executionInfo":{"status":"ok","timestamp":1614977505865,"user_tz":480,"elapsed":370155,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["dg = data_setup()\n","norm_data = dg.df()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9wW2uwChFXH","executionInfo":{"status":"ok","timestamp":1614977506600,"user_tz":480,"elapsed":732,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from data_transformation import get_isotope_data, get_hydrocarbs\n","isotope_data = get_isotope_data()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLlJSWfDhFXH","executionInfo":{"status":"ok","timestamp":1614977507036,"user_tz":480,"elapsed":1165,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from data_transformation import get_suspicious_peaks, get_peak_suspiciousness, get_ranges\n","original_data = dg.calibrated_df(True, .005, .01,use_ranges=True, ranges=[0, 0, 0.5], cat=True)\n","ranges = get_ranges(isotope_data, 2000)\n","original_data['target'] = original_data['target'].apply(lambda a: a - 1 if a > 0 else a)\n","original_data['sus_peaks'] = original_data['masses'].apply(get_suspicious_peaks, args=(ranges, .1))\n","original_data['peak_sussness'] = original_data['masses'].apply(get_peak_suspiciousness, args=(ranges, True))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"yri-8Y1VhFXI","executionInfo":{"status":"ok","timestamp":1614977510455,"user_tz":480,"elapsed":4582,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["df = pd.read_csv('../data/processed_cas.csv')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"84fro-ghhFXI"},"source":["test = df['Calibration'][3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1sH7-ONhFXJ","executionInfo":{"status":"ok","timestamp":1614977510456,"user_tz":480,"elapsed":4582,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["labels = []\n","positions = []\n","for row in df.itertuples():\n","    for split in row.Calibration.split(')')[:-1]:\n","        calibrators = split.split('(')[1].split(',')\n","        if calibrators[1] not in labels:\n","            labels.append(calibrators[1])\n","            positions.append(float(calibrators[2].strip()))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tvOKMb_hFXJ","executionInfo":{"status":"ok","timestamp":1614977510457,"user_tz":480,"elapsed":4581,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["df2 = pd.DataFrame({'labels': labels, 'positions': positions})\n","df2 = df2.sort_values('positions', ascending=False).reset_index(drop=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmrSxgyGhFXJ","executionInfo":{"status":"ok","timestamp":1614977510457,"user_tz":480,"elapsed":4579,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["def get_x(masses, intensities, x=12, thresh=0.1):\n","    '''\n","    Get all peaks in data near a specific mass x.\n","    '''\n","    row_x = -1\n","    max = -1\n","    for i, mass in enumerate(masses):\n","        dif = abs(mass-x)\n","        inten = intensities[i]\n","        if dif < thresh and (inten > max or max == -1):\n","            max = inten\n","            row_x = dif\n","    return row_x"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"6P3V3or3hFXK","executionInfo":{"status":"ok","timestamp":1614977510458,"user_tz":480,"elapsed":4578,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["training_data = pd.DataFrame(columns=list(df2['labels'])+['target'])"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lifbq1GNhFXK","executionInfo":{"status":"ok","timestamp":1614977511861,"user_tz":480,"elapsed":5978,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from data_transformation import generate_data\n","# 10,000 Examples only offset error\n","erred = generate_data(norm_data, 2, 2, True, [0, 0, 0])\n","for _ in range(10):\n","    erred = pd.concat([erred, generate_data(norm_data, 2, 2, True, [0, 0, 1], True)], axis=0)\n","#erred['target'] = erred['target'].apply(lambda a: a - 1 if a > 0 else a)\n","dg.set_df(erred)\n","erred = dg.calibrated_df()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPLIlVT_hFXK","executionInfo":{"status":"ok","timestamp":1614977630938,"user_tz":480,"elapsed":125054,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["for i, row in enumerate(erred.itertuples()):\n","    dists = []\n","    for pos in df2['positions']:\n","        dists.append(get_x(row.masses, row.intensities, x=pos, thresh=0.1))\n","    training_data.loc[i] = dists + [row.target]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Gr9vQR6hFXK","executionInfo":{"status":"ok","timestamp":1614977630942,"user_tz":480,"elapsed":125056,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from sklearn.model_selection import train_test_split\n","X = training_data.drop('target', axis=1)\n","X = X.to_numpy().reshape(9966, 309, 1)\n","y = training_data['target']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"4L0F3iyyhFXK","executionInfo":{"status":"ok","timestamp":1614977638287,"user_tz":480,"elapsed":132399,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["from tensorflow.keras.layers import Dense, Flatten, Input, Conv1D, BatchNormalization\n","from tensorflow.keras.layers import AveragePooling1D, MaxPooling1D, Layer, Concatenate\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras import Model, Sequential"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ADvGLsIhFXL","executionInfo":{"status":"ok","timestamp":1614977638288,"user_tz":480,"elapsed":132398,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}}},"source":["def lenet():\n","    model = Sequential()\n","\n","    model.add(Conv1D(filters=8, kernel_size=10, activation='tanh', input_shape=(309, 1)))\n","    model.add(AveragePooling1D())\n","\n","    model.add(Conv1D(filters=16, kernel_size=20, activation='tanh'))\n","    model.add(AveragePooling1D())\n","\n","    model.add(Flatten())\n","\n","    model.add(Dense(units=500, activation='tanh'))\n","\n","    model.add(Dense(units=100, activation='tanh'))\n","\n","    model.add(Dense(units=2, activation = 'softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n","    return model"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4AatRFNhFXL","executionInfo":{"status":"ok","timestamp":1614978028237,"user_tz":480,"elapsed":522339,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"}},"outputId":"cc76e31b-7724-4cb3-86ea-82dd680c71f7"},"source":["estimator2 = KerasClassifier(build_fn = lenet, epochs = 300, batch_size = 30, verbose = 1, class_weight={0:11, 1:1})\n","estimator2.fit(X_train, y_train)\n","preds2 = estimator2.predict_proba(X_test)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/300\n","266/266 [==============================] - 34s 4ms/step - loss: 1.5213 - accuracy: 0.4929 - auc: 0.5017\n","Epoch 2/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.2598 - accuracy: 0.5340 - auc: 0.5477\n","Epoch 3/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.2001 - accuracy: 0.5284 - auc: 0.5793\n","Epoch 4/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.1514 - accuracy: 0.5003 - auc: 0.5966\n","Epoch 5/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.1017 - accuracy: 0.5052 - auc: 0.6074\n","Epoch 6/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.0624 - accuracy: 0.5934 - auc: 0.6830\n","Epoch 7/300\n","266/266 [==============================] - 1s 5ms/step - loss: 1.0958 - accuracy: 0.5330 - auc: 0.6499\n","Epoch 8/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.0693 - accuracy: 0.5453 - auc: 0.6624\n","Epoch 9/300\n","266/266 [==============================] - 1s 4ms/step - loss: 1.0085 - accuracy: 0.5717 - auc: 0.6892\n","Epoch 10/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.9883 - accuracy: 0.6070 - auc: 0.7217\n","Epoch 11/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.9955 - accuracy: 0.6025 - auc: 0.7155\n","Epoch 12/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.9650 - accuracy: 0.6189 - auc: 0.7361\n","Epoch 13/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.9566 - accuracy: 0.5774 - auc: 0.7084\n","Epoch 14/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.9452 - accuracy: 0.6126 - auc: 0.7319\n","Epoch 15/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.6117 - auc: 0.7435\n","Epoch 16/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.9126 - accuracy: 0.6346 - auc: 0.7576\n","Epoch 17/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8841 - accuracy: 0.6347 - auc: 0.7655\n","Epoch 18/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8952 - accuracy: 0.6130 - auc: 0.7476\n","Epoch 19/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.9129 - accuracy: 0.5768 - auc: 0.7204\n","Epoch 20/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.9010 - accuracy: 0.5996 - auc: 0.7466\n","Epoch 21/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.8768 - accuracy: 0.6554 - auc: 0.7836\n","Epoch 22/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.8574 - accuracy: 0.6146 - auc: 0.7696\n","Epoch 23/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8598 - accuracy: 0.6324 - auc: 0.7629\n","Epoch 24/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8512 - accuracy: 0.5991 - auc: 0.7499\n","Epoch 25/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8391 - accuracy: 0.6163 - auc: 0.7703\n","Epoch 26/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8261 - accuracy: 0.6512 - auc: 0.7870\n","Epoch 27/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.8803 - accuracy: 0.6537 - auc: 0.7802\n","Epoch 28/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8242 - accuracy: 0.6259 - auc: 0.7740\n","Epoch 29/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8076 - accuracy: 0.6262 - auc: 0.7834\n","Epoch 30/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8184 - accuracy: 0.5970 - auc: 0.7610\n","Epoch 31/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.8679 - accuracy: 0.6439 - auc: 0.7763\n","Epoch 32/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8224 - accuracy: 0.6252 - auc: 0.7848\n","Epoch 33/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7942 - accuracy: 0.6226 - auc: 0.7845\n","Epoch 34/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8020 - accuracy: 0.6703 - auc: 0.8113\n","Epoch 35/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8095 - accuracy: 0.6920 - auc: 0.8236\n","Epoch 36/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7666 - accuracy: 0.6457 - auc: 0.8041\n","Epoch 37/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7867 - accuracy: 0.6637 - auc: 0.8030\n","Epoch 38/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8078 - accuracy: 0.6567 - auc: 0.7992\n","Epoch 39/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7805 - accuracy: 0.6201 - auc: 0.7899\n","Epoch 40/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7758 - accuracy: 0.6420 - auc: 0.8006\n","Epoch 41/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.8054 - accuracy: 0.6256 - auc: 0.7832\n","Epoch 42/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7400 - accuracy: 0.6645 - auc: 0.8164\n","Epoch 43/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7796 - accuracy: 0.6156 - auc: 0.7875\n","Epoch 44/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7649 - accuracy: 0.6330 - auc: 0.7982\n","Epoch 45/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7816 - accuracy: 0.6530 - auc: 0.8044\n","Epoch 46/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7913 - accuracy: 0.6389 - auc: 0.7916\n","Epoch 47/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7341 - accuracy: 0.6914 - auc: 0.8350\n","Epoch 48/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7717 - accuracy: 0.6480 - auc: 0.8085\n","Epoch 49/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7320 - accuracy: 0.6625 - auc: 0.8203\n","Epoch 50/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7847 - accuracy: 0.6306 - auc: 0.7973\n","Epoch 51/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7394 - accuracy: 0.6754 - auc: 0.8223\n","Epoch 52/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7204 - accuracy: 0.6629 - auc: 0.8185\n","Epoch 53/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7342 - accuracy: 0.6580 - auc: 0.8180\n","Epoch 54/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7328 - accuracy: 0.6670 - auc: 0.8183\n","Epoch 55/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7426 - accuracy: 0.6662 - auc: 0.8238\n","Epoch 56/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7239 - accuracy: 0.7245 - auc: 0.8556\n","Epoch 57/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7999 - accuracy: 0.6357 - auc: 0.7938\n","Epoch 58/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7430 - accuracy: 0.6338 - auc: 0.8072\n","Epoch 59/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7392 - accuracy: 0.6509 - auc: 0.8156\n","Epoch 60/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7463 - accuracy: 0.6155 - auc: 0.7988\n","Epoch 61/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7528 - accuracy: 0.6399 - auc: 0.8148\n","Epoch 62/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7239 - accuracy: 0.6911 - auc: 0.8369\n","Epoch 63/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7188 - accuracy: 0.6421 - auc: 0.8161\n","Epoch 64/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7521 - accuracy: 0.6064 - auc: 0.7898\n","Epoch 65/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7057 - accuracy: 0.6718 - auc: 0.8324\n","Epoch 66/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7466 - accuracy: 0.6220 - auc: 0.8004\n","Epoch 67/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7414 - accuracy: 0.6386 - auc: 0.8167\n","Epoch 68/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7098 - accuracy: 0.6823 - auc: 0.8320\n","Epoch 69/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.6421 - auc: 0.8157\n","Epoch 70/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.6331 - auc: 0.8170\n","Epoch 71/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.7026 - auc: 0.8457\n","Epoch 72/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7428 - accuracy: 0.6402 - auc: 0.8111\n","Epoch 73/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.6676 - auc: 0.8257\n","Epoch 74/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7104 - accuracy: 0.6781 - auc: 0.8308\n","Epoch 75/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7076 - accuracy: 0.6564 - auc: 0.8177\n","Epoch 76/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7241 - accuracy: 0.6420 - auc: 0.8164\n","Epoch 77/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.6362 - auc: 0.8148\n","Epoch 78/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7382 - accuracy: 0.6316 - auc: 0.8077\n","Epoch 79/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7152 - accuracy: 0.6671 - auc: 0.8288\n","Epoch 80/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7065 - accuracy: 0.6291 - auc: 0.8121\n","Epoch 81/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7069 - accuracy: 0.6454 - auc: 0.8241\n","Epoch 82/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7426 - accuracy: 0.6399 - auc: 0.8196\n","Epoch 83/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7050 - accuracy: 0.6558 - auc: 0.8286\n","Epoch 84/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7391 - accuracy: 0.6358 - auc: 0.8176\n","Epoch 85/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7488 - accuracy: 0.6559 - auc: 0.8201\n","Epoch 86/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.6993 - auc: 0.8405\n","Epoch 87/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7184 - accuracy: 0.6891 - auc: 0.8360\n","Epoch 88/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7106 - accuracy: 0.6379 - auc: 0.8139\n","Epoch 89/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7234 - accuracy: 0.6345 - auc: 0.8145\n","Epoch 90/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7053 - accuracy: 0.6219 - auc: 0.8102\n","Epoch 91/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.6325 - auc: 0.8191\n","Epoch 92/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7202 - accuracy: 0.6427 - auc: 0.8161\n","Epoch 93/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7064 - accuracy: 0.6552 - auc: 0.8264\n","Epoch 94/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7141 - accuracy: 0.6508 - auc: 0.8210\n","Epoch 95/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7175 - accuracy: 0.6544 - auc: 0.8242\n","Epoch 96/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7050 - accuracy: 0.6812 - auc: 0.8360\n","Epoch 97/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7129 - accuracy: 0.6640 - auc: 0.8340\n","Epoch 98/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7296 - accuracy: 0.6617 - auc: 0.8275\n","Epoch 99/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.6345 - auc: 0.8122\n","Epoch 100/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7323 - accuracy: 0.6254 - auc: 0.8096\n","Epoch 101/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6845 - accuracy: 0.6627 - auc: 0.8317\n","Epoch 102/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7117 - accuracy: 0.6247 - auc: 0.8189\n","Epoch 103/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7312 - accuracy: 0.6388 - auc: 0.8172\n","Epoch 104/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7065 - accuracy: 0.6312 - auc: 0.8166\n","Epoch 105/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7266 - accuracy: 0.6496 - auc: 0.8208\n","Epoch 106/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7036 - accuracy: 0.6669 - auc: 0.8336\n","Epoch 107/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7218 - accuracy: 0.6565 - auc: 0.8250\n","Epoch 108/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7383 - accuracy: 0.6460 - auc: 0.8174\n","Epoch 109/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7152 - accuracy: 0.6438 - auc: 0.8216\n","Epoch 110/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6846 - accuracy: 0.6991 - auc: 0.8492\n","Epoch 111/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.6501 - auc: 0.8315\n","Epoch 112/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.6392 - auc: 0.8217\n","Epoch 113/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7028 - accuracy: 0.6315 - auc: 0.8205\n","Epoch 114/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7422 - accuracy: 0.6235 - auc: 0.8102\n","Epoch 115/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.6769 - auc: 0.8397\n","Epoch 116/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.6431 - auc: 0.8245\n","Epoch 117/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6581 - accuracy: 0.6783 - auc: 0.8482\n","Epoch 118/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6766 - accuracy: 0.6656 - auc: 0.8330\n","Epoch 119/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.6749 - auc: 0.8428\n","Epoch 120/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6922 - accuracy: 0.6500 - auc: 0.8342\n","Epoch 121/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.6691 - auc: 0.8367\n","Epoch 122/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6923 - accuracy: 0.6590 - auc: 0.8282\n","Epoch 123/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.6599 - auc: 0.8300\n","Epoch 124/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6810 - accuracy: 0.6957 - auc: 0.8460\n","Epoch 125/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6894 - accuracy: 0.6782 - auc: 0.8431\n","Epoch 126/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6697 - accuracy: 0.6931 - auc: 0.8534\n","Epoch 127/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.6812 - auc: 0.8434\n","Epoch 128/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.6578 - auc: 0.8342\n","Epoch 129/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.6527 - auc: 0.8331\n","Epoch 130/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6801 - accuracy: 0.6890 - auc: 0.8511\n","Epoch 131/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6900 - accuracy: 0.6940 - auc: 0.8481\n","Epoch 132/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.6783 - auc: 0.8383\n","Epoch 133/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6629 - accuracy: 0.6935 - auc: 0.8526\n","Epoch 134/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6810 - accuracy: 0.6611 - auc: 0.8334\n","Epoch 135/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6739 - accuracy: 0.6739 - auc: 0.8429\n","Epoch 136/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6689 - accuracy: 0.6948 - auc: 0.8502\n","Epoch 137/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6664 - accuracy: 0.6900 - auc: 0.8489\n","Epoch 138/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7156 - accuracy: 0.6609 - auc: 0.8336\n","Epoch 139/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7113 - accuracy: 0.6699 - auc: 0.8363\n","Epoch 140/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7029 - accuracy: 0.6529 - auc: 0.8291\n","Epoch 141/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.6565 - auc: 0.8289\n","Epoch 142/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6949 - accuracy: 0.6746 - auc: 0.8336\n","Epoch 143/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6839 - accuracy: 0.6776 - auc: 0.8437\n","Epoch 144/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6363 - accuracy: 0.7446 - auc: 0.8802\n","Epoch 145/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6504 - accuracy: 0.6949 - auc: 0.8507\n","Epoch 146/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.6450 - auc: 0.8263\n","Epoch 147/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7082 - accuracy: 0.6662 - auc: 0.8364\n","Epoch 148/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6957 - accuracy: 0.6623 - auc: 0.8305\n","Epoch 149/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.6667 - auc: 0.8387\n","Epoch 150/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7092 - accuracy: 0.6603 - auc: 0.8365\n","Epoch 151/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6764 - accuracy: 0.6957 - auc: 0.8521\n","Epoch 152/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6862 - accuracy: 0.6465 - auc: 0.8328\n","Epoch 153/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6819 - accuracy: 0.6852 - auc: 0.8434\n","Epoch 154/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6674 - accuracy: 0.6784 - auc: 0.8435\n","Epoch 155/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.6515 - auc: 0.8319\n","Epoch 156/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.6949 - auc: 0.8517\n","Epoch 157/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.6778 - auc: 0.8433\n","Epoch 158/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6472 - accuracy: 0.6842 - auc: 0.8508\n","Epoch 159/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6787 - accuracy: 0.6601 - auc: 0.8386\n","Epoch 160/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.6749 - auc: 0.8427\n","Epoch 161/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.6721 - auc: 0.8425\n","Epoch 162/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.6810 - auc: 0.8480\n","Epoch 163/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7147 - accuracy: 0.6728 - auc: 0.8390\n","Epoch 164/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7080 - accuracy: 0.6623 - auc: 0.8363\n","Epoch 165/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7023 - accuracy: 0.6572 - auc: 0.8338\n","Epoch 166/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6928 - accuracy: 0.6574 - auc: 0.8337\n","Epoch 167/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6739 - accuracy: 0.6621 - auc: 0.8396\n","Epoch 168/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6885 - accuracy: 0.6490 - auc: 0.8275\n","Epoch 169/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6578 - accuracy: 0.6845 - auc: 0.8472\n","Epoch 170/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6963 - accuracy: 0.6878 - auc: 0.8458\n","Epoch 171/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6734 - accuracy: 0.6975 - auc: 0.8528\n","Epoch 172/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7031 - accuracy: 0.6433 - auc: 0.8314\n","Epoch 173/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6837 - accuracy: 0.6651 - auc: 0.8371\n","Epoch 174/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6706 - accuracy: 0.6990 - auc: 0.8581\n","Epoch 175/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7046 - accuracy: 0.6753 - auc: 0.8375\n","Epoch 176/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6847 - accuracy: 0.6625 - auc: 0.8363\n","Epoch 177/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6774 - accuracy: 0.6682 - auc: 0.8409\n","Epoch 178/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6689 - accuracy: 0.6310 - auc: 0.8273\n","Epoch 179/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6724 - accuracy: 0.6334 - auc: 0.8281\n","Epoch 180/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6928 - accuracy: 0.6833 - auc: 0.8471\n","Epoch 181/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7024 - accuracy: 0.6428 - auc: 0.8282\n","Epoch 182/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.6552 - auc: 0.8283\n","Epoch 183/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.6587 - auc: 0.8378\n","Epoch 184/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.6403 - auc: 0.8283\n","Epoch 185/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6629 - accuracy: 0.6697 - auc: 0.8452\n","Epoch 186/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6865 - accuracy: 0.6609 - auc: 0.8364\n","Epoch 187/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6722 - accuracy: 0.6694 - auc: 0.8426\n","Epoch 188/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7030 - accuracy: 0.6411 - auc: 0.8315\n","Epoch 189/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6980 - accuracy: 0.6528 - auc: 0.8303\n","Epoch 190/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.6566 - auc: 0.8352\n","Epoch 191/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7054 - accuracy: 0.6740 - auc: 0.8394\n","Epoch 192/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.6903 - auc: 0.8505\n","Epoch 193/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6656 - accuracy: 0.6462 - auc: 0.8342\n","Epoch 194/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6681 - accuracy: 0.6544 - auc: 0.8384\n","Epoch 195/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7002 - accuracy: 0.6643 - auc: 0.8374\n","Epoch 196/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6870 - accuracy: 0.6668 - auc: 0.8414\n","Epoch 197/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 0.6543 - auc: 0.8341\n","Epoch 198/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6782 - accuracy: 0.6670 - auc: 0.8403\n","Epoch 199/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.6446 - auc: 0.8312\n","Epoch 200/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6749 - accuracy: 0.6752 - auc: 0.8388\n","Epoch 201/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.6537 - auc: 0.8335\n","Epoch 202/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6584 - accuracy: 0.7019 - auc: 0.8561\n","Epoch 203/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6578 - accuracy: 0.6905 - auc: 0.8573\n","Epoch 204/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6997 - accuracy: 0.6500 - auc: 0.8317\n","Epoch 205/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.6619 - auc: 0.8328\n","Epoch 206/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6736 - accuracy: 0.6480 - auc: 0.8337\n","Epoch 207/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6761 - accuracy: 0.6757 - auc: 0.8471\n","Epoch 208/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6705 - accuracy: 0.6673 - auc: 0.8446\n","Epoch 209/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6495 - accuracy: 0.7374 - auc: 0.8753\n","Epoch 210/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6972 - accuracy: 0.6467 - auc: 0.8335\n","Epoch 211/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6491 - accuracy: 0.6885 - auc: 0.8500\n","Epoch 212/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6829 - accuracy: 0.6627 - auc: 0.8381\n","Epoch 213/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.6341 - auc: 0.8231\n","Epoch 214/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6725 - accuracy: 0.6522 - auc: 0.8378\n","Epoch 215/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6863 - accuracy: 0.6529 - auc: 0.8360\n","Epoch 216/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6602 - accuracy: 0.6837 - auc: 0.8474\n","Epoch 217/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6549 - accuracy: 0.6789 - auc: 0.8450\n","Epoch 218/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6655 - accuracy: 0.6578 - auc: 0.8397\n","Epoch 219/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6675 - accuracy: 0.6708 - auc: 0.8437\n","Epoch 220/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6692 - accuracy: 0.6719 - auc: 0.8451\n","Epoch 221/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6501 - accuracy: 0.6867 - auc: 0.8546\n","Epoch 222/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6830 - accuracy: 0.6880 - auc: 0.8486\n","Epoch 223/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.6701 - auc: 0.8378\n","Epoch 224/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6498 - accuracy: 0.6577 - auc: 0.8397\n","Epoch 225/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.6299 - auc: 0.8249\n","Epoch 226/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.6993 - auc: 0.8545\n","Epoch 227/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6688 - accuracy: 0.6467 - auc: 0.8340\n","Epoch 228/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6504 - accuracy: 0.6913 - auc: 0.8553\n","Epoch 229/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.6744 - auc: 0.8435\n","Epoch 230/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6448 - accuracy: 0.7140 - auc: 0.8615\n","Epoch 231/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.6628 - auc: 0.8389\n","Epoch 232/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6630 - accuracy: 0.6665 - auc: 0.8397\n","Epoch 233/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.6467 - auc: 0.8318\n","Epoch 234/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6405 - accuracy: 0.7245 - auc: 0.8696\n","Epoch 235/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6596 - accuracy: 0.6657 - auc: 0.8392\n","Epoch 236/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6436 - accuracy: 0.7207 - auc: 0.8620\n","Epoch 237/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.6505 - auc: 0.8309\n","Epoch 238/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6858 - accuracy: 0.6395 - auc: 0.8256\n","Epoch 239/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.6811 - auc: 0.8481\n","Epoch 240/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6755 - accuracy: 0.6977 - auc: 0.8588\n","Epoch 241/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6490 - accuracy: 0.6760 - auc: 0.8490\n","Epoch 242/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6525 - accuracy: 0.6721 - auc: 0.8447\n","Epoch 243/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6550 - accuracy: 0.6910 - auc: 0.8517\n","Epoch 244/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.6314 - auc: 0.8270\n","Epoch 245/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.7191 - auc: 0.8641\n","Epoch 246/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.6512 - auc: 0.8322\n","Epoch 247/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.6574 - auc: 0.8376\n","Epoch 248/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6788 - accuracy: 0.6696 - auc: 0.8441\n","Epoch 249/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7402 - accuracy: 0.6637 - auc: 0.8430\n","Epoch 250/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6915 - accuracy: 0.6837 - auc: 0.8455\n","Epoch 251/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6535 - accuracy: 0.6513 - auc: 0.8392\n","Epoch 252/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.6546 - auc: 0.8380\n","Epoch 253/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6988 - accuracy: 0.6585 - auc: 0.8381\n","Epoch 254/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.6795 - auc: 0.8395\n","Epoch 255/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.7042 - accuracy: 0.6650 - auc: 0.8330\n","Epoch 256/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.6671 - auc: 0.8444\n","Epoch 257/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6596 - accuracy: 0.6535 - auc: 0.8398\n","Epoch 258/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.6450 - auc: 0.8323\n","Epoch 259/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6665 - accuracy: 0.6607 - auc: 0.8408\n","Epoch 260/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6674 - accuracy: 0.6658 - auc: 0.8451\n","Epoch 261/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6726 - accuracy: 0.6560 - auc: 0.8337\n","Epoch 262/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6590 - accuracy: 0.7052 - auc: 0.8565\n","Epoch 263/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6685 - accuracy: 0.6369 - auc: 0.8305\n","Epoch 264/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6733 - accuracy: 0.6626 - auc: 0.8367\n","Epoch 265/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6727 - accuracy: 0.6531 - auc: 0.8371\n","Epoch 266/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6303 - accuracy: 0.6818 - auc: 0.8501\n","Epoch 267/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6989 - accuracy: 0.6596 - auc: 0.8386\n","Epoch 268/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6772 - accuracy: 0.6388 - auc: 0.8320\n","Epoch 269/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6901 - accuracy: 0.6529 - auc: 0.8363\n","Epoch 270/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.6500 - auc: 0.8327\n","Epoch 271/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6974 - accuracy: 0.6349 - auc: 0.8245\n","Epoch 272/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6559 - accuracy: 0.6629 - auc: 0.8440\n","Epoch 273/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6892 - accuracy: 0.6683 - auc: 0.8387\n","Epoch 274/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6357 - accuracy: 0.7250 - auc: 0.8702\n","Epoch 275/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.6334 - auc: 0.8200\n","Epoch 276/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.6347 - auc: 0.8275\n","Epoch 277/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6792 - accuracy: 0.6610 - auc: 0.8340\n","Epoch 278/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6424 - accuracy: 0.6511 - auc: 0.8369\n","Epoch 279/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6660 - accuracy: 0.6794 - auc: 0.8408\n","Epoch 280/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6417 - accuracy: 0.6597 - auc: 0.8405\n","Epoch 281/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6805 - accuracy: 0.6547 - auc: 0.8364\n","Epoch 282/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.6915 - auc: 0.8522\n","Epoch 283/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.6663 - auc: 0.8430\n","Epoch 284/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6983 - accuracy: 0.6876 - auc: 0.8464\n","Epoch 285/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6365 - accuracy: 0.6847 - auc: 0.8486\n","Epoch 286/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6751 - accuracy: 0.6787 - auc: 0.8462\n","Epoch 287/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6611 - accuracy: 0.6539 - auc: 0.8401\n","Epoch 288/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6408 - auc: 0.8352\n","Epoch 289/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6707 - accuracy: 0.6778 - auc: 0.8462\n","Epoch 290/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6399 - accuracy: 0.6894 - auc: 0.8530\n","Epoch 291/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.6477 - auc: 0.8320\n","Epoch 292/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6606 - accuracy: 0.6369 - auc: 0.8315\n","Epoch 293/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.6358 - auc: 0.8266\n","Epoch 294/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6733 - accuracy: 0.6856 - auc: 0.8490\n","Epoch 295/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.7087 - accuracy: 0.6720 - auc: 0.8424\n","Epoch 296/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6652 - accuracy: 0.6672 - auc: 0.8397\n","Epoch 297/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6686 - accuracy: 0.6605 - auc: 0.8378\n","Epoch 298/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6473 - accuracy: 0.6597 - auc: 0.8416\n","Epoch 299/300\n","266/266 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.6398 - auc: 0.8321\n","Epoch 300/300\n","266/266 [==============================] - 1s 5ms/step - loss: 0.6607 - accuracy: 0.6749 - auc: 0.8478\n","40/67 [================>.............] - ETA: 0s"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n","  warnings.warn('`model.predict_proba()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["67/67 [==============================] - 0s 2ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"jdjFc0fEhFXM"},"source":["import tensorflow.keras as keras\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8x6tjAW_v1ED"},"source":["def calculate_metrics(y_true, y_pred, duration):\n","    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n","                       columns=['precision', 'accuracy', 'recall', 'duration'])\n","    res['precision'] = precision_score(y_true, y_pred, average='macro')\n","    res['accuracy'] = accuracy_score(y_true, y_pred)\n","    res['recall'] = recall_score(y_true, y_pred, average='macro')\n","    res['duration'] = duration\n","    return res\n","\n","\n","def save_test_duration(file_name, test_duration):\n","    res = pd.DataFrame(data=np.zeros((1, 1), dtype=np.float), index=[0],\n","                       columns=['test_duration'])\n","    res['test_duration'] = test_duration\n","    res.to_csv(file_name, index=False)\n","\n","def save_logs(output_directory, hist, y_pred, y_true, duration,\n","              lr=True, plot_test_acc=True):\n","    hist_df = pd.DataFrame(hist.history)\n","    hist_df.to_csv(output_directory + 'history.csv', index=False)\n","\n","    df_metrics = calculate_metrics(y_true, y_pred, duration)\n","    df_metrics.to_csv(output_directory + 'df_metrics.csv', index=False)\n","\n","    index_best_model = hist_df['loss'].idxmin()\n","    row_best_model = hist_df.loc[index_best_model]\n","\n","    df_best_model = pd.DataFrame(data=np.zeros((1, 6), dtype=np.float), index=[0],\n","                                 columns=['best_model_train_loss', 'best_model_val_loss', 'best_model_train_acc',\n","                                          'best_model_val_acc', 'best_model_learning_rate', 'best_model_nb_epoch'])\n","\n","    df_best_model['best_model_train_loss'] = row_best_model['loss']\n","    if plot_test_acc:\n","        df_best_model['best_model_val_loss'] = row_best_model['val_loss']\n","    df_best_model['best_model_train_acc'] = row_best_model['acc']\n","    if plot_test_acc:\n","        df_best_model['best_model_val_acc'] = row_best_model['val_acc']\n","    if lr == True:\n","        df_best_model['best_model_learning_rate'] = row_best_model['lr']\n","    df_best_model['best_model_nb_epoch'] = index_best_model\n","\n","    df_best_model.to_csv(output_directory + 'df_best_model.csv', index=False)\n","\n","    if plot_test_acc:\n","        # plot losses\n","        plot_epochs_metric(hist, output_directory + 'epochs_loss.png')\n","\n","    return df_metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Tt-CuB5VoebS"},"source":["class Classifier_INCEPTION:\n","\n","    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, batch_size=64,\n","                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n","\n","        self.output_directory = output_directory\n","\n","        self.nb_filters = nb_filters\n","        self.use_residual = use_residual\n","        self.use_bottleneck = use_bottleneck\n","        self.depth = depth\n","        self.kernel_size = kernel_size - 1\n","        self.callbacks = None\n","        self.batch_size = batch_size\n","        self.bottleneck_size = 32\n","        self.nb_epochs = nb_epochs\n","\n","        if build == True:\n","            self.model = self.build_model(input_shape, nb_classes)\n","            if (verbose == True):\n","                self.model.summary()\n","            self.verbose = verbose\n","            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n","\n","    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n","\n","        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n","            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n","                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n","        else:\n","            input_inception = input_tensor\n","\n","        # kernel_size_s = [3, 5, 8, 11, 17]\n","        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n","\n","        conv_list = []\n","\n","        for i in range(len(kernel_size_s)):\n","            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n","                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n","                input_inception))\n","\n","        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n","\n","        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n","                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n","\n","        conv_list.append(conv_6)\n","\n","        x = keras.layers.Concatenate(axis=2)(conv_list)\n","        x = keras.layers.BatchNormalization()(x)\n","        x = keras.layers.Activation(activation='relu')(x)\n","        return x\n","\n","    def _shortcut_layer(self, input_tensor, out_tensor):\n","        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n","                                         padding='same', use_bias=False)(input_tensor)\n","        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","        x = keras.layers.Add()([shortcut_y, out_tensor])\n","        x = keras.layers.Activation('relu')(x)\n","        return x\n","\n","    def build_model(self, input_shape, nb_classes):\n","        input_layer = keras.layers.Input(input_shape)\n","\n","        x = input_layer\n","        input_res = input_layer\n","\n","        for d in range(self.depth):\n","\n","            x = self._inception_module(x)\n","\n","            if self.use_residual and d % 3 == 2:\n","                x = self._shortcut_layer(input_res, x)\n","                input_res = x\n","\n","        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n","\n","        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n","\n","        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n","                      metrics=['accuracy'])\n","\n","        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n","                                                      min_lr=0.0001)\n","\n","        file_path = self.output_directory + 'best_model.hdf5'\n","\n","        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n","                                                           save_best_only=True)\n","\n","        self.callbacks = [reduce_lr, model_checkpoint]\n","\n","        return model\n","\n","    def fit(self, x_train, y_train, x_val, y_val, y_true, plot_test_acc=False, class_weights=None):\n","        if not tf.test.gpu_device_name():\n","            print('error no gpu')\n","            exit()\n","        # x_val and y_val are only used to monitor the test loss and NOT for training\n","\n","        if self.batch_size is None:\n","            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n","        else:\n","            mini_batch_size = self.batch_size\n","\n","        start_time = time.time()\n","\n","        if plot_test_acc:\n","\n","            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n","                                  verbose=self.verbose, validation_data=(x_val, y_val),\n","                                  callbacks=self.callbacks, class_weight=class_weights)\n","        else:\n","\n","            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n","                                  verbose=self.verbose, callbacks=self.callbacks, class_weight=class_weights)\n","\n","        duration = time.time() - start_time\n","\n","        self.model.save(self.output_directory + 'last_model.hdf5')\n","\n","        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val,\n","                              return_df_metrics=False)\n","\n","        # save predictions\n","        np.save(self.output_directory + 'y_pred.npy', y_pred)\n","\n","        # convert the predicted from binary to integer\n","        #y_pred = np.argmax(y_pred, axis=1)\n","\n","        #df_metrics = save_logs(self.output_directory, hist, y_pred, y_true, duration,\n","        #                       plot_test_acc=plot_test_acc)\n","\n","        keras.backend.clear_session()\n","\n","        return y_pred\n","\n","    def predict(self, x_test, y_true, x_train, y_train, y_test, return_df_metrics=False):\n","        start_time = time.time()\n","        model_path = self.output_directory + 'best_model.hdf5'\n","        model = keras.models.load_model(model_path)\n","        y_pred = model.predict(x_test, batch_size=self.batch_size)\n","        if return_df_metrics:\n","            y_pred = np.argmax(y_pred, axis=1)\n","            df_metrics = calculate_metrics(y_true, y_pred, 0.0)\n","            return df_metrics\n","        else:\n","            test_duration = time.time() - start_time\n","            save_test_duration(self.output_directory + 'test_duration.csv', test_duration)\n","            return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9juiVU1_om8F","executionInfo":{"elapsed":828,"status":"ok","timestamp":1614820305229,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"},"user_tz":480},"outputId":"7f668a18-5659-44cc-b4ab-0fb179899bde"},"source":["c = Classifier_INCEPTION('../', (309, 1), 2, build=True, verbose=True, batch_size=20, nb_epochs=100, depth=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 309, 1)]     0                                            \n","__________________________________________________________________________________________________\n","max_pooling1d_15 (MaxPooling1D) (None, 309, 1)       0           input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_82 (Conv1D)              (None, 309, 32)      1280        input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_83 (Conv1D)              (None, 309, 32)      640         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_84 (Conv1D)              (None, 309, 32)      320         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_85 (Conv1D)              (None, 309, 32)      32          max_pooling1d_15[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 309, 128)     0           conv1d_82[0][0]                  \n","                                                                 conv1d_83[0][0]                  \n","                                                                 conv1d_84[0][0]                  \n","                                                                 conv1d_85[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 309, 128)     512         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 309, 128)     0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_86 (Conv1D)              (None, 309, 32)      4096        activation_20[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling1d_16 (MaxPooling1D) (None, 309, 128)     0           activation_20[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_87 (Conv1D)              (None, 309, 32)      40960       conv1d_86[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_88 (Conv1D)              (None, 309, 32)      20480       conv1d_86[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_89 (Conv1D)              (None, 309, 32)      10240       conv1d_86[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_90 (Conv1D)              (None, 309, 32)      4096        max_pooling1d_16[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 309, 128)     0           conv1d_87[0][0]                  \n","                                                                 conv1d_88[0][0]                  \n","                                                                 conv1d_89[0][0]                  \n","                                                                 conv1d_90[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 309, 128)     512         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 309, 128)     0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_91 (Conv1D)              (None, 309, 32)      4096        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling1d_17 (MaxPooling1D) (None, 309, 128)     0           activation_21[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_92 (Conv1D)              (None, 309, 32)      40960       conv1d_91[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_93 (Conv1D)              (None, 309, 32)      20480       conv1d_91[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_94 (Conv1D)              (None, 309, 32)      10240       conv1d_91[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_95 (Conv1D)              (None, 309, 32)      4096        max_pooling1d_17[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 309, 128)     0           conv1d_92[0][0]                  \n","                                                                 conv1d_93[0][0]                  \n","                                                                 conv1d_94[0][0]                  \n","                                                                 conv1d_95[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_96 (Conv1D)              (None, 309, 128)     128         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 309, 128)     512         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 309, 128)     512         conv1d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 309, 128)     0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 309, 128)     0           batch_normalization_23[0][0]     \n","                                                                 activation_22[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 309, 128)     0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling1d_5 (Glo (None, 128)          0           activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 2)            258         global_average_pooling1d_5[0][0] \n","==================================================================================================\n","Total params: 164,450\n","Trainable params: 163,426\n","Non-trainable params: 1,024\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"s6-3dBvNozpc"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"SBHJL3jdouxe"},"source":["y_train_dummies = np.array(pd.get_dummies(y_train))\n","y_val_dummies =  np.array(pd.get_dummies(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"SElw7RU9ovR1","outputId":"ea13a8e4-970e-4af5-ee8b-3a070ec5520d"},"source":["import time\n","c.fit(X_train, y_train_dummies, X_test, y_val_dummies, y_val_dummies, class_weights={0:10, 1:1})"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-a354c45342f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"]}]},{"cell_type":"code","metadata":{"id":"IzQ4i5ampD7Z"},"source":["preds = c.predict(X_train, y_train, X_train, y_train, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2d3588NduVvl","executionInfo":{"elapsed":533,"status":"ok","timestamp":1614821249931,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"},"user_tz":480},"outputId":"2391a9d6-c876-4447-f8ad-4dcca727dde3"},"source":["predictions = []\n","for i in range(len(preds)):\n","    predictions.append(np.where(preds[i]==max(preds[i]))[0][0])\n","accuracy_score(y_train, predictions)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9233567486201706"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mb0BTc2e1EN6","executionInfo":{"elapsed":291,"status":"ok","timestamp":1614821180497,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"},"user_tz":480},"outputId":"3f61d95f-f6a8-40ec-f9f8-4f63284025fe"},"source":["y_test[60:70]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4375    1.0\n","9927    1.0\n","1347    1.0\n","6123    1.0\n","9727    1.0\n","2485    1.0\n","107     0.0\n","6162    1.0\n","2517    1.0\n","3209    1.0\n","Name: target, dtype: float64"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"He7H4qAp1n5d","executionInfo":{"elapsed":391,"status":"ok","timestamp":1614821208183,"user":{"displayName":"Warren Register","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN7Wja7DSoALRpu3eATQH0nUFvY5rFY5yaljwIbw=s64","userId":"14502775680021541472"},"user_tz":480},"outputId":"1b96b6d0-46e4-4ed2-db68-d94fb09760e9"},"source":["preds[66]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.03952207, 0.96047795], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"id":"EIC6C9ax1sZl"},"source":[""],"execution_count":null,"outputs":[]}]}